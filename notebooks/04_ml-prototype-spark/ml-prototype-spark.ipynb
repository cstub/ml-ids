{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled ML Prototype\n",
    "\n",
    "This notebook implements the scaled version of the ML Prototype created in the previous notebook.  \n",
    "\n",
    "The scaled version of the ML Prototype facilitates PySpark to create a [Pipeline](https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/ml/Pipeline.html) cleaning the dataset and to train a [GBTClassifier](https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/ml/classification/GBTClassifier.html) using grid-search.  \n",
    "Both the pipeline and the classifier are serialized to disk for further usage.  \n",
    "\n",
    "This notebook is separated into four parts:\n",
    "1. Common code: Contains the common code used in all other parts of the notebook.\n",
    "2. Dataset creation: The [CIC-IDS-2018](https://drive.google.com/open?id=1HrTPh0YRSZ4T9DLa_c47lubheKUcPl0r) and [CIC-IDS-2017](https://drive.google.com/open?id=1Q2J_pPB0K0PHjq0YO5BPwYQwrvoZgYqo) datasets are mixed and split into training and holdout datasets. The training dataset is used to train and evaluate a classifier whereas the holdout dataset may be used to utilise the classifier in practice in absence of further real-world data.\n",
    "3. Model training: In this section the pipeline to clean and impute the data is created and a GBTClassifier is trained on the data via grid-search. The pipeline and the classifier are serialized to disk as a last step.\n",
    "4. Model Usage: This part of the notebook demonstrates the usage of the classifier. Both the pipeline and the classifier are read from disk to perform predictions on the holdout dataset. This section can be used as a basis for a separate driver program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Common code\n",
    "\n",
    "The following section contains the common code used in the later parts of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Paths\n",
    "dataset_path = r'/home/glados/Development/Projects/ids-201?/processed/*.csv'\n",
    "spark_output_path = r'/home/glados/Development/Projects/ids-spark/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, ShortType, IntegerType, LongType, FloatType, DoubleType, TimestampType, StringType\n",
    "from pyspark.sql.functions import count, when, col\n",
    "from pyspark.ml import Pipeline, Transformer, PipelineModel\n",
    "from pyspark.ml.param.shared import HasOutputCols, HasInputCols, Param, Params\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.ml.feature import Imputer, OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier, GBTClassificationModel\n",
    "from pyspark.ml.tuning import CrossValidatorModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from functools import reduce\n",
    "import os\n",
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = os.path.join(spark_output_path, 'training')\n",
    "holdout_path = os.path.join(spark_output_path, 'holdout')\n",
    "pipeline_model_path = 'models/spark/pipeline-model'\n",
    "gb_model_path = 'models/spark/gb-model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Features\n",
    "\n",
    "The following features were used to train the ML Prototype (LINK) and are subsequently used to train the GBTClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'protocol',\n",
    "    'flow_duration',\n",
    "    'tot_fwd_pkts',\n",
    "    'tot_bwd_pkts',\n",
    "    'totlen_fwd_pkts',\n",
    "    'totlen_bwd_pkts',\n",
    "    'fwd_pkt_len_mean',\n",
    "    'fwd_pkt_len_std',\n",
    "    'bwd_pkt_len_mean',\n",
    "    'flow_byts_s',\n",
    "    'flow_pkts_s',\n",
    "    'flow_iat_std',\n",
    "    'flow_iat_min',\n",
    "    'fwd_iat_tot',\n",
    "    'fwd_iat_min',\n",
    "    'bwd_iat_tot',\n",
    "    'bwd_iat_min',\n",
    "    'fwd_psh_flags',\n",
    "    'fwd_urg_flags',\n",
    "    'bwd_pkts_s',\n",
    "    'fin_flag_cnt',\n",
    "    'rst_flag_cnt',\n",
    "    'psh_flag_cnt',\n",
    "    'ack_flag_cnt',\n",
    "    'urg_flag_cnt',\n",
    "    'down_up_ratio',\n",
    "    'init_fwd_win_byts',\n",
    "    'init_bwd_win_byts',\n",
    "    'fwd_seg_size_min',\n",
    "    'active_mean',\n",
    "    'idle_mean'\n",
    "]\n",
    "\n",
    "selected_columns = selected_features + ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Schema\n",
    "\n",
    "The following contains the schema of the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('dst_port', IntegerType()),\n",
    "    StructField('protocol', IntegerType()),\n",
    "    StructField('timestamp', StringType()),\n",
    "    StructField('flow_duration', LongType()),\n",
    "    StructField('tot_fwd_pkts', IntegerType()),\n",
    "    StructField('tot_bwd_pkts', IntegerType()),\n",
    "    StructField('totlen_fwd_pkts', DoubleType()),\n",
    "    StructField('totlen_bwd_pkts', DoubleType()),\n",
    "    StructField('fwd_pkt_len_max', DoubleType()),\n",
    "    StructField('fwd_pkt_len_min', DoubleType()),\n",
    "    StructField('fwd_pkt_len_mean', DoubleType()),\n",
    "    StructField('fwd_pkt_len_std', DoubleType()),\n",
    "    StructField('bwd_pkt_len_max', DoubleType()),\n",
    "    StructField('bwd_pkt_len_min', DoubleType()),\n",
    "    StructField('bwd_pkt_len_mean', DoubleType()),\n",
    "    StructField('bwd_pkt_len_std', DoubleType()),\n",
    "    StructField('flow_byts_s', StringType()),\n",
    "    StructField('flow_pkts_s', StringType()),\n",
    "    StructField('flow_iat_mean', DoubleType()),\n",
    "    StructField('flow_iat_std', DoubleType()),\n",
    "    StructField('flow_iat_max', DoubleType()),\n",
    "    StructField('flow_iat_min', DoubleType()),\n",
    "    StructField('fwd_iat_tot', DoubleType()),\n",
    "    StructField('fwd_iat_mean', DoubleType()),\n",
    "    StructField('fwd_iat_std', DoubleType()),\n",
    "    StructField('fwd_iat_max', DoubleType()),\n",
    "    StructField('fwd_iat_min', DoubleType()),\n",
    "    StructField('bwd_iat_tot', DoubleType()),\n",
    "    StructField('bwd_iat_mean', DoubleType()),\n",
    "    StructField('bwd_iat_std', DoubleType()),\n",
    "    StructField('bwd_iat_max', DoubleType()),\n",
    "    StructField('bwd_iat_min', DoubleType()),\n",
    "    StructField('fwd_psh_flags', IntegerType()),\n",
    "    StructField('bwd_psh_flags', IntegerType()),\n",
    "    StructField('fwd_urg_flags', IntegerType()),\n",
    "    StructField('bwd_urg_flags', IntegerType()),\n",
    "    StructField('fwd_header_len', LongType()),\n",
    "    StructField('bwd_header_len', IntegerType()),\n",
    "    StructField('fwd_pkts_s', DoubleType()),\n",
    "    StructField('bwd_pkts_s', DoubleType()),\n",
    "    StructField('pkt_len_min', DoubleType()),\n",
    "    StructField('pkt_len_max', DoubleType()),\n",
    "    StructField('pkt_len_mean', DoubleType()),\n",
    "    StructField('pkt_len_std', DoubleType()),\n",
    "    StructField('pkt_len_var', DoubleType()),\n",
    "    StructField('fin_flag_cnt', IntegerType()),\n",
    "    StructField('syn_flag_cnt', IntegerType()),\n",
    "    StructField('rst_flag_cnt', IntegerType()),\n",
    "    StructField('psh_flag_cnt', IntegerType()),\n",
    "    StructField('ack_flag_cnt', IntegerType()),\n",
    "    StructField('urg_flag_cnt', IntegerType()),\n",
    "    StructField('cwe_flag_count', IntegerType()),\n",
    "    StructField('ece_flag_cnt', IntegerType()),\n",
    "    StructField('down_up_ratio', DoubleType()),\n",
    "    StructField('pkt_size_avg', DoubleType()),\n",
    "    StructField('fwd_seg_size_avg', DoubleType()),\n",
    "    StructField('bwd_seg_size_avg', DoubleType()),\n",
    "    StructField('fwd_byts_b_avg', IntegerType()),\n",
    "    StructField('fwd_pkts_b_avg', IntegerType()),\n",
    "    StructField('fwd_blk_rate_avg', IntegerType()),\n",
    "    StructField('bwd_byts_b_avg', IntegerType()),\n",
    "    StructField('bwd_pkts_b_avg', IntegerType()),\n",
    "    StructField('bwd_blk_rate_avg', IntegerType()),\n",
    "    StructField('subflow_fwd_pkts', IntegerType()),\n",
    "    StructField('subflow_fwd_byts', IntegerType()),\n",
    "    StructField('subflow_bwd_pkts', IntegerType()),\n",
    "    StructField('subflow_bwd_byts', IntegerType()),\n",
    "    StructField('init_fwd_win_byts', IntegerType()),\n",
    "    StructField('init_bwd_win_byts', IntegerType()),\n",
    "    StructField('fwd_act_data_pkts', IntegerType()),\n",
    "    StructField('fwd_seg_size_min', IntegerType()),\n",
    "    StructField('active_mean', DoubleType()),\n",
    "    StructField('active_std', DoubleType()),\n",
    "    StructField('active_max', DoubleType()),\n",
    "    StructField('active_min', DoubleType()),\n",
    "    StructField('idle_mean', DoubleType()),\n",
    "    StructField('idle_std', DoubleType()),\n",
    "    StructField('idle_max', DoubleType()),\n",
    "    StructField('idle_min', DoubleType()),\n",
    "    StructField('label', StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Common classes and functions\n",
    "\n",
    "The following cell contains common classes and functions used in the later sections of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLabelMaker(Transformer, HasOutputCols, HasInputCols, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    '''\n",
    "    A transformer that adds binary labels (0|1) based on the value of the input colums. \n",
    "    The \"classLabel\" parameter specifies the value of the input columns used to determine class 0.\n",
    "    '''\n",
    "    \n",
    "    classLabel = Param(Params._dummy(), 'classLabel', 'label for class 0')\n",
    "    \n",
    "    def __init__(self, inputCols=None, outputCols=None, classLabel=''):\n",
    "        super(BinaryLabelMaker, self).__init__()\n",
    "        self._set(inputCols=inputCols)\n",
    "        self._set(outputCols=outputCols)\n",
    "        self._set(classLabel=classLabel)\n",
    "\n",
    "    def setClassLabel(self, classLabel):\n",
    "        return self._set(classLabel=classLabel)\n",
    "\n",
    "    def getClassLabel(self):\n",
    "        return self.getOrDefault(self.classLabel)\n",
    "    \n",
    "    def _make_label(self, df, inputCol, outputCol):\n",
    "        return df.withColumn(outputCol, when(df[inputCol] == self.getClassLabel(), 0).otherwise(1).cast(DoubleType()))\n",
    "        \n",
    "    def _transform(self, df):\n",
    "        cols = zip(self.getInputCols(), self.getOutputCols())\n",
    "        return reduce(lambda acc, col: self._make_label(acc, col[0], col[1]), cols, df)\n",
    "    \n",
    "    \n",
    "class ValueCleaner(Transformer, HasOutputCols, HasInputCols, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    '''\n",
    "    A transformer that removes invalid values from the input columns.\n",
    "    Invalid values are \"inf\" and values < 0.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, inputCols=None, outputCols=None):\n",
    "        super(ValueCleaner, self).__init__()\n",
    "        self._set(inputCols=inputCols)\n",
    "        self._set(outputCols=outputCols)\n",
    "        \n",
    "    @staticmethod    \n",
    "    def _replace_invalid_values(df, inputCol, outputCol, replacement):   \n",
    "        return (df.withColumn(outputCol, \n",
    "                              when(df[inputCol] == 'inf', replacement)\n",
    "                              .when(df[inputCol] < 0.0, replacement)\n",
    "                              .otherwise(df[inputCol])\n",
    "                              .cast(DoubleType())\n",
    "                             ))\n",
    "    \n",
    "    def _transform(self, df):\n",
    "        cols = zip(self.getInputCols(), self.getOutputCols())\n",
    "        return reduce(lambda acc, col: ValueCleaner._replace_invalid_values(acc, col[0], col[1], None), cols, df)\n",
    "    \n",
    "\n",
    "def load_csv(path, columns=None):\n",
    "    df = (spark.read\n",
    "          .schema(schema)\n",
    "          .option('inferSchema', 'false')\n",
    "          .option('header', 'true')\n",
    "          .option('sep', ',')\n",
    "          .csv(path))\n",
    "    \n",
    "    if columns:\n",
    "        return df.select(*columns)\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "\n",
    "def find_columns_to_impute(df):\n",
    "    col_values = df.select([count(when(col(c).isNull(), c).when(col(c) < 0.0, c).when(col(c) == 'inf', c)).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "    return [k for k, v in col_values.items() if v > 0]\n",
    "\n",
    "\n",
    "def cat_column_name(c):\n",
    "    return f\"{c}_cat\"\n",
    "\n",
    "\n",
    "def index_column_name(c):\n",
    "    return f\"{c}_idx\"\n",
    "\n",
    "\n",
    "def imputed_column_name(c):\n",
    "    return f\"{c}_imputed\"\n",
    "\n",
    "\n",
    "def print_classification_report(predictions, pred_col, label_col, report_type):\n",
    "    predictionAndLabels = predictions.select(pred_col, label_col).rdd\n",
    "    \n",
    "    binary_metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
    "    multi_metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=label_col)\n",
    "    aupr = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderPR\"})\n",
    "    \n",
    "    print(f'Classification Report ({report_type}):')\n",
    "    print(f'Recall: {multi_metrics.weightedRecall}')\n",
    "    print(f'Precision: {multi_metrics.weightedPrecision}')\n",
    "    print(f'F1: {multi_metrics.weightedFMeasure()}')\n",
    "    print(f'FPR: {multi_metrics.weightedFalsePositiveRate}')\n",
    "    print(f'TPR: {multi_metrics.weightedTruePositiveRate}')\n",
    "    print()\n",
    "    print(f'Area under PR (raw predictions): {aupr}')\n",
    "    print(f'Area under PR: {binary_metrics.areaUnderPR}')\n",
    "    print(f'Accuracy = {multi_metrics.accuracy}')\n",
    "    print()\n",
    "    print('Confusion Matrix:')\n",
    "    print(multi_metrics.confusionMatrix())\n",
    "\n",
    "    \n",
    "def find_columns_with_value(df, value):\n",
    "    col_values = df.select([count(when(col(c) == value, c)).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "    return [k for k, v in col_values.items() if v > 0]\n",
    "\n",
    "\n",
    "def find_neg_columns(df):\n",
    "    col_values = df.select([count(when(col(c) < 0.0, c)).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "    return [k for k, v in col_values.items() if v > 0]\n",
    "\n",
    "\n",
    "def find_null_columns(df):\n",
    "    col_values = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "    return [k for k, v in col_values.items() if v > 0]\n",
    "\n",
    "\n",
    "def assert_column_validity(df):\n",
    "    impute_cols = find_columns_to_impute(df)\n",
    "    assert len(impute_cols) == 0, f'Invalid columns found {impute_cols}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Spark Session\n",
    "\n",
    "A SparkSession is created configured with 3 executors using all cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "    .master('local[*]')\n",
    "    .appName('ml-ids')\n",
    "    .config('spark.executor.instances', '3')\n",
    "    .config('spark.executor.cores', '3')\n",
    "    .config('spark.executor.memory', '15g')\n",
    "    .config('spark.driver.memory', '15g')\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset creation\n",
    "\n",
    "In this part both the [CIC-IDS-2018](https://drive.google.com/open?id=1HrTPh0YRSZ4T9DLa_c47lubheKUcPl0r) and [CIC-IDS-2017](https://drive.google.com/open?id=1Q2J_pPB0K0PHjq0YO5BPwYQwrvoZgYqo) datasets are loaded, combined and split into a training and holdout dataset with the ratio of `90%/10%`.   \n",
    "Both respective datasets are subsequently saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data samples: 17157022\n",
      "Holdout samples: 1906664\n",
      "Writing training set...\n",
      "Writing holdout set...\n"
     ]
    }
   ],
   "source": [
    "df = load_csv(dataset_path)\n",
    "\n",
    "(training_df, hold_df) = df.randomSplit([0.9, 0.1], seed=42)\n",
    "\n",
    "print(f\"Data samples: {training_df.count()}\")\n",
    "print(f\"Holdout samples: {hold_df.count()}\")\n",
    "\n",
    "print('Writing training set...')\n",
    "training_df.write.csv(training_path, header='true', mode='overwrite')\n",
    "\n",
    "print('Writing holdout set...')\n",
    "hold_df.write.csv(holdout_path, header='true', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As both datasets contain invalid values as well as empty values all columns that have to be processed are determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to impute:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['flow_duration',\n",
       " 'flow_byts_s',\n",
       " 'flow_pkts_s',\n",
       " 'flow_iat_min',\n",
       " 'fwd_iat_tot',\n",
       " 'fwd_iat_min',\n",
       " 'init_fwd_win_byts',\n",
       " 'init_bwd_win_byts',\n",
       " 'fwd_seg_size_min']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_cols = find_columns_to_impute(df.select(*selected_features))\n",
    "print(f'Columns to impute:')\n",
    "impute_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "In this section a pipeline is created in order to remove invalid values and impute missing values in the dataset. Afterwards a GBTClassifier is trained on the data using grid-search.  \n",
    "Both the pipeline and the classifier are serialized to disk as a last step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_cols = [\n",
    "    'flow_duration',\n",
    "    'flow_byts_s',\n",
    "    'flow_pkts_s',\n",
    "    'flow_iat_min',\n",
    "    'fwd_iat_tot',\n",
    "    'fwd_iat_min',\n",
    "    'init_fwd_win_byts',\n",
    "    'init_bwd_win_byts',\n",
    "    'fwd_seg_size_min'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_csv(os.path.join(training_path, '*.csv'), selected_columns).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature columns\n",
    "\n",
    "The feature columns of the classifier are defined in order to create the pipeline in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature columns: 31\n",
      "Feature columns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tot_fwd_pkts',\n",
       " 'tot_bwd_pkts',\n",
       " 'totlen_fwd_pkts',\n",
       " 'totlen_bwd_pkts',\n",
       " 'fwd_pkt_len_mean',\n",
       " 'fwd_pkt_len_std',\n",
       " 'bwd_pkt_len_mean',\n",
       " 'flow_iat_std',\n",
       " 'bwd_iat_tot',\n",
       " 'bwd_iat_min',\n",
       " 'fwd_psh_flags',\n",
       " 'fwd_urg_flags',\n",
       " 'bwd_pkts_s',\n",
       " 'fin_flag_cnt',\n",
       " 'rst_flag_cnt',\n",
       " 'psh_flag_cnt',\n",
       " 'ack_flag_cnt',\n",
       " 'urg_flag_cnt',\n",
       " 'down_up_ratio',\n",
       " 'active_mean',\n",
       " 'idle_mean',\n",
       " 'protocol_cat',\n",
       " 'flow_duration_imputed',\n",
       " 'flow_byts_s_imputed',\n",
       " 'flow_pkts_s_imputed',\n",
       " 'flow_iat_min_imputed',\n",
       " 'fwd_iat_tot_imputed',\n",
       " 'fwd_iat_min_imputed',\n",
       " 'init_fwd_win_byts_imputed',\n",
       " 'init_bwd_win_byts_imputed',\n",
       " 'fwd_seg_size_min_imputed']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = ['protocol']\n",
    "\n",
    "cleaned_impute_cols = [f'{c}_clean' for c in impute_cols]\n",
    "\n",
    "processed_cols = cat_cols + impute_cols\n",
    "unprocessed_cols = [c for c in selected_features if c not in processed_cols] \n",
    "feature_cols = (unprocessed_cols + \n",
    "                [cat_column_name(c) for c in cat_cols] +\n",
    "                [imputed_column_name(c) for c in impute_cols])\n",
    "\n",
    "print(f'Number of feature columns: {len(feature_cols)}')\n",
    "print('Feature columns:')\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Pipeline Creation\n",
    "\n",
    "In this section the pipeline to process the input data is created. The pipeline consists of the following stages:\n",
    "1. `ValueCleaner`: sets all values to `None` which have a value of `inf` or `<0` in order to be imputed in the next stage.\n",
    "2. `Imputer`: Imputes all missing values with the mean value of the column.\n",
    "3. `OneHotEncoderEstimator`: One-hot encodes the `protocol` category column.\n",
    "4. `VectorAssembler`: Merges all feature columns into a feature vector column. \n",
    "5. `BinaryLabelMaker`: Adds a binary label with value `0 = Benign` and `1 = Attack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []\n",
    "\n",
    "# ValueCleaner\n",
    "cleaner = ValueCleaner(inputCols=impute_cols, outputCols=cleaned_impute_cols)\n",
    "stages += [cleaner]\n",
    "\n",
    "# Imputer\n",
    "imputer = Imputer(\n",
    "    inputCols=cleaned_impute_cols, \n",
    "    outputCols=[imputed_column_name(c) for c in impute_cols]\n",
    ")\n",
    "stages += [imputer]\n",
    "\n",
    "# OneHotEncoderEstimator\n",
    "for c in cat_cols:\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[c], outputCols=[cat_column_name(c)])\n",
    "    stages += [encoder]\n",
    "    \n",
    "# VetorAssembler\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "stages += [assembler]    \n",
    "\n",
    "# LabelMaker\n",
    "label_maker = BinaryLabelMaker(\n",
    "    inputCols=['label'], \n",
    "    outputCols=['label_is_attack'],\n",
    "    classLabel='Benign'    \n",
    ")\n",
    "stages += [label_maker]\n",
    "\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Pipeline Fitting\n",
    "\n",
    "In this step the pipeline is fitted, the training dataset is transformed and the validity of the resulting dataset is asserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(train_df)\n",
    "train_transf_df = pipeline_model.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_column_validity(train_transf_df.select(feature_cols).drop('protocol_cat').drop('features'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Dataset Preparation\n",
    "\n",
    "The dataset is splitted into training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 13728637\n",
      "Test samples: 3428385\n"
     ]
    }
   ],
   "source": [
    "(training_data, test_data) = train_transf_df.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f'Training samples: {training_data.count()}')\n",
    "print(f'Test samples: {test_data.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Model Training\n",
    "\n",
    "In this section the GBTClassifier is trained using grid-search with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "Max depth: 5\n",
      "Max iterations: 20\n",
      "Step size: 0.5\n"
     ]
    }
   ],
   "source": [
    "gb = GBTClassifier(labelCol='label_is_attack', featuresCol='features', seed=42)\n",
    "\n",
    "param_grid = (ParamGridBuilder()\n",
    "              .addGrid(gb.maxDepth, [1, 3, 5])\n",
    "              .addGrid(gb.maxIter, [10, 20])\n",
    "              .addGrid(gb.stepSize, [0.5, 0.1, 0.05])\n",
    "              .build())\n",
    "\n",
    "evaluator = (MulticlassClassificationEvaluator(predictionCol=\"prediction\", \n",
    "                                               labelCol='label_is_attack',\n",
    "                                               metricName='weightedRecall'))\n",
    "\n",
    "cv = (CrossValidator(estimator=gb,\n",
    "                     estimatorParamMaps=param_grid,\n",
    "                     evaluator=evaluator,\n",
    "                     numFolds=3))\n",
    "\n",
    "gb_model = cv.fit(training_data)\n",
    "\n",
    "print('Best parameters:')\n",
    "print(f'Max depth: {gb_model.bestModel._java_obj.getMaxDepth()}')\n",
    "print(f'Max iterations: {gb_model.bestModel._java_obj.getMaxIter()}')\n",
    "print(f'Step size: {gb_model.bestModel._java_obj.getStepSize()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Train):\n",
      "Recall: 0.9875890082897523\n",
      "Precision: 0.9875789062812305\n",
      "F1: 0.9874730933711836\n",
      "FPR: 0.04899706171213246\n",
      "TPR: 0.9875890082897523\n",
      "\n",
      "Area under PR (raw predictions): 0.9776131473914916\n",
      "Area under PR: 0.9626597197081999\n",
      "Accuracy = 0.9875890082897523\n",
      "\n",
      "Confusion Matrix:\n",
      "DenseMatrix([[11317165.,    30602.],\n",
      "             [  139784.,  2241086.]])\n"
     ]
    }
   ],
   "source": [
    "train_pred = gb_model.transform(training_data)\n",
    "print_classification_report(train_pred, 'prediction', 'label_is_attack', 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Test):\n",
      "Recall: 0.9875626570528105\n",
      "Precision: 0.9875525094295057\n",
      "F1: 0.9874458377349316\n",
      "FPR: 0.04922211493411625\n",
      "TPR: 0.9875626570528105\n",
      "\n",
      "Area under PR (raw predictions): 0.97758372423304\n",
      "Area under PR: 0.9625211546722784\n",
      "Accuracy = 0.9875626570528105\n",
      "\n",
      "Confusion Matrix:\n",
      "DenseMatrix([[2827204.,    7643.],\n",
      "             [  34997.,  558541.]])\n"
     ]
    }
   ],
   "source": [
    "test_pred = gb_model.transform(test_data)\n",
    "print_classification_report(test_pred, 'prediction', 'label_is_attack', 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the model is promising with a recall of `0.988` and a precision of `0.988` on the test set.    \n",
    "The following table summarizes the performance on the test set:  \n",
    "\n",
    "|Precision|Recall|F1|Area under PR|\n",
    "|---------|------|--|-------------|\n",
    "|0.988|0.988|0.988|0.978|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Model Persistence\n",
    "\n",
    "In the last step of this section the models for the pipeline and the GBTClassifier are persisted to disk in order to be used independent of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model.write().overwrite().save(pipeline_model_path)\n",
    "gb_model.write().overwrite().save(gb_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Usage\n",
    "\n",
    "This section demonstrates the usage of the classifier trained in the previous section. Models for the pipeline and the GBTClassifier are read from disk in order to perform predictions on the holdout dataset.  \n",
    "This section can be used as a basis for a separate driver program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Pipeline and GBTClassifier Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = PipelineModel.load(pipeline_model_path)\n",
    "gb_model = CrossValidatorModel.load(gb_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Holdout Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout samples: 1906664\n"
     ]
    }
   ],
   "source": [
    "hold_df = load_csv(os.path.join(holdout_path, '*.csv'), selected_columns).cache()\n",
    "print(f\"Holdout samples: {hold_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Pipeline Application\n",
    "\n",
    "The pipeline is applied to the dataset, asserting the validity of all values in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_transf_df = pipeline_model.transform(hold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_column_validity(hold_transf_df.select(feature_cols).drop('protocol_cat').drop('features'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Predictions on the Holdout Dataset\n",
    "\n",
    "The classifier is applied to the holdout dataset, printing the classification report for the resulting predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Holdout):\n",
      "Recall: 0.9876931646058246\n",
      "Precision: 0.9876838348438507\n",
      "F1: 0.9875794596235876\n",
      "FPR: 0.04846458013698347\n",
      "TPR: 0.9876931646058246\n",
      "\n",
      "Area under PR (raw predictions): 0.9777125841930321\n",
      "Area under PR: 0.9630935075027023\n",
      "Accuracy = 0.9876931646058246\n",
      "\n",
      "Confusion Matrix:\n",
      "DenseMatrix([[1570985.,    4206.],\n",
      "             [  19259.,  312214.]])\n"
     ]
    }
   ],
   "source": [
    "hold_pred = gb_model.transform(hold_transf_df)\n",
    "print_classification_report(hold_pred, 'prediction', 'label_is_attack', 'Holdout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
