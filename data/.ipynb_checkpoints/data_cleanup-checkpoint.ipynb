{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup\n",
    "\n",
    "Before the CSE-CIC-IDS2018 dataset can be used for analysis and training the dataset has to be cleaned. In its raw format the dataset consists of ten individual csv files, each containing the recorded network traffic of a single day of operation, named after the day the traffic was recorded on.\n",
    "\n",
    "To conduct an initial analysis of the dataset a single file is loaded and dissected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set base path to the directory containing the csv files of the dataset\n",
    "dataset_base_path = r'/path/to/dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Removing invalid rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/spark/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(dataset_base_path, 'Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv')\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the output of `read_csv` shows that for most of the columns pandas could not infer a datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 331125 entries, 0 to 331124\n",
      "Data columns (total 80 columns):\n",
      "Dst Port             331125 non-null object\n",
      "Protocol             331125 non-null object\n",
      "Timestamp            331125 non-null object\n",
      "Flow Duration        331125 non-null object\n",
      "Tot Fwd Pkts         331125 non-null object\n",
      "Tot Bwd Pkts         331125 non-null object\n",
      "TotLen Fwd Pkts      331125 non-null object\n",
      "TotLen Bwd Pkts      331125 non-null object\n",
      "Fwd Pkt Len Max      331125 non-null object\n",
      "Fwd Pkt Len Min      331125 non-null object\n",
      "Fwd Pkt Len Mean     331125 non-null object\n",
      "Fwd Pkt Len Std      331125 non-null object\n",
      "Bwd Pkt Len Max      331125 non-null object\n",
      "Bwd Pkt Len Min      331125 non-null object\n",
      "Bwd Pkt Len Mean     331125 non-null object\n",
      "Bwd Pkt Len Std      331125 non-null object\n",
      "Flow Byts/s          329291 non-null object\n",
      "Flow Pkts/s          331125 non-null object\n",
      "Flow IAT Mean        331125 non-null object\n",
      "Flow IAT Std         331125 non-null object\n",
      "Flow IAT Max         331125 non-null object\n",
      "Flow IAT Min         331125 non-null object\n",
      "Fwd IAT Tot          331125 non-null object\n",
      "Fwd IAT Mean         331125 non-null object\n",
      "Fwd IAT Std          331125 non-null object\n",
      "Fwd IAT Max          331125 non-null object\n",
      "Fwd IAT Min          331125 non-null object\n",
      "Bwd IAT Tot          331125 non-null object\n",
      "Bwd IAT Mean         331125 non-null object\n",
      "Bwd IAT Std          331125 non-null object\n",
      "Bwd IAT Max          331125 non-null object\n",
      "Bwd IAT Min          331125 non-null object\n",
      "Fwd PSH Flags        331125 non-null object\n",
      "Bwd PSH Flags        331125 non-null object\n",
      "Fwd URG Flags        331125 non-null object\n",
      "Bwd URG Flags        331125 non-null object\n",
      "Fwd Header Len       331125 non-null object\n",
      "Bwd Header Len       331125 non-null object\n",
      "Fwd Pkts/s           331125 non-null object\n",
      "Bwd Pkts/s           331125 non-null object\n",
      "Pkt Len Min          331125 non-null object\n",
      "Pkt Len Max          331125 non-null object\n",
      "Pkt Len Mean         331125 non-null object\n",
      "Pkt Len Std          331125 non-null object\n",
      "Pkt Len Var          331125 non-null object\n",
      "FIN Flag Cnt         331125 non-null object\n",
      "SYN Flag Cnt         331125 non-null object\n",
      "RST Flag Cnt         331125 non-null object\n",
      "PSH Flag Cnt         331125 non-null object\n",
      "ACK Flag Cnt         331125 non-null object\n",
      "URG Flag Cnt         331125 non-null object\n",
      "CWE Flag Count       331125 non-null object\n",
      "ECE Flag Cnt         331125 non-null object\n",
      "Down/Up Ratio        331125 non-null object\n",
      "Pkt Size Avg         331125 non-null object\n",
      "Fwd Seg Size Avg     331125 non-null object\n",
      "Bwd Seg Size Avg     331125 non-null object\n",
      "Fwd Byts/b Avg       331125 non-null object\n",
      "Fwd Pkts/b Avg       331125 non-null object\n",
      "Fwd Blk Rate Avg     331125 non-null object\n",
      "Bwd Byts/b Avg       331125 non-null object\n",
      "Bwd Pkts/b Avg       331125 non-null object\n",
      "Bwd Blk Rate Avg     331125 non-null object\n",
      "Subflow Fwd Pkts     331125 non-null object\n",
      "Subflow Fwd Byts     331125 non-null object\n",
      "Subflow Bwd Pkts     331125 non-null object\n",
      "Subflow Bwd Byts     331125 non-null object\n",
      "Init Fwd Win Byts    331125 non-null object\n",
      "Init Bwd Win Byts    331125 non-null object\n",
      "Fwd Act Data Pkts    331125 non-null object\n",
      "Fwd Seg Size Min     331125 non-null object\n",
      "Active Mean          331125 non-null object\n",
      "Active Std           331125 non-null object\n",
      "Active Max           331125 non-null object\n",
      "Active Min           331125 non-null object\n",
      "Idle Mean            331125 non-null object\n",
      "Idle Std             331125 non-null object\n",
      "Idle Max             331125 non-null object\n",
      "Idle Min             331125 non-null object\n",
      "Label                331125 non-null object\n",
      "dtypes: object(80)\n",
      "memory usage: 202.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying the `info()` method of the dataframe shows that pandas inferred all columns as `object` columns as opposed to  numerical columns which would be appropriate for most of them.\n",
    "In order to understand why the columns are interpreted as `object`s low cardinality columns are analyzed to show individual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6           170066\n",
       "17           95674\n",
       "6            42833\n",
       "17           15378\n",
       "0             4596\n",
       "0             2553\n",
       "Protocol        25\n",
       "Name: Protocol, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Protocol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               268629\n",
       "0                60520\n",
       "1                 1707\n",
       "1                  244\n",
       "FIN Flag Cnt        25\n",
       "Name: FIN Flag Cnt, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FIN Flag Cnt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique values indicate the existence of the column name as values in the dataset. \n",
    "A visual examination of the input file confirms that the headers are present multiple times within the file, interweaved with the raw data rows. This suggests that a single file was created by concatenating mulitple csv files duplicating the headers in the process.\n",
    "To fix this issue all columns containing the headers are removed from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Dst Port'].str.contains('Dst Port', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next steps the dataframe is exported to a temporary csv file in order to read it again with the correct column datatypes. \n",
    "Furthermore the column names are converted to lowercase with non-word characters removed for easier access of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "tmp_path = os.path.join(dataset_base_path, 'tmp')\n",
    "\n",
    "if not os.path.exists(tmp_path):\n",
    "    os.mkdir(tmp_path)\n",
    "\n",
    "column_name_regex = re.compile(r\"\\W\", re.IGNORECASE)\n",
    "df.columns = [column_name_regex.sub('_', c.lower()) for c in df.columns]\n",
    "\n",
    "tmp_file_path = os.path.join(tmp_path, 'Thursday-01-03-2018_TrafficForML_CICFlowMeter_duplicate_headers_removed.csv')\n",
    "\n",
    "df.to_csv(tmp_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Removing invalid values\n",
    "\n",
    "Now the temporary file is loaded with the following datatype definitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {\n",
    "    'dst_port': 'uint32',\n",
    "    'protocol': 'uint8',\n",
    "    'timestamp': 'object',\n",
    "    'flow_duration': 'int64',\n",
    "    'tot_fwd_pkts': 'uint32',\n",
    "    'tot_bwd_pkts': 'uint32',\n",
    "    'totlen_fwd_pkts': 'uint32',\n",
    "    'totlen_bwd_pkts': 'uint32',\n",
    "    'fwd_pkt_len_max': 'uint16',\n",
    "    'fwd_pkt_len_min': 'uint16',\n",
    "    'fwd_pkt_len_mean': 'float32',\n",
    "    'fwd_pkt_len_std': 'float32',\n",
    "    'bwd_pkt_len_max': 'uint16',\n",
    "    'bwd_pkt_len_min': 'uint16',\n",
    "    'bwd_pkt_len_mean': 'float32',\n",
    "    'bwd_pkt_len_std': 'float32',\n",
    "    'flow_byts_s': 'float64',\n",
    "    'flow_pkts_s': 'float64',\n",
    "    'flow_iat_mean': 'float32',\n",
    "    'flow_iat_std': 'float32',\n",
    "    'flow_iat_max': 'int64',\n",
    "    'flow_iat_min': 'int64',\n",
    "    'fwd_iat_tot': 'int64',\n",
    "    'fwd_iat_mean': 'float32',\n",
    "    'fwd_iat_std': 'float32',\n",
    "    'fwd_iat_max': 'int64',\n",
    "    'fwd_iat_min': 'int64',\n",
    "    'bwd_iat_tot': 'uint32',\n",
    "    'bwd_iat_mean': 'float32',\n",
    "    'bwd_iat_std': 'float32',\n",
    "    'bwd_iat_max': 'uint32',\n",
    "    'bwd_iat_min': 'uint32',\n",
    "    'fwd_psh_flags': 'uint8',\n",
    "    'bwd_psh_flags': 'uint8',\n",
    "    'fwd_urg_flags': 'uint8',\n",
    "    'bwd_urg_flags': 'uint8',\n",
    "    'fwd_header_len': 'uint32',\n",
    "    'bwd_header_len': 'uint32',\n",
    "    'flow_byts_s': 'float32',\n",
    "    'bwd_pkts_s': 'float32',\n",
    "    'pkt_len_min': 'uint16',\n",
    "    'pkt_len_max': 'uint16',\n",
    "    'pkt_len_mean': 'float32',\n",
    "    'pkt_len_std': 'float32',\n",
    "    'pkt_len_var': 'float32',\n",
    "    'fin_flag_cnt': 'uint8',\n",
    "    'syn_flag_cnt': 'uint8',\n",
    "    'rst_flag_cnt': 'uint8',\n",
    "    'psh_flag_cnt': 'uint8',\n",
    "    'ack_flag_cnt': 'uint8',\n",
    "    'urg_flag_cnt': 'uint8',\n",
    "    'cwe_flag_count': 'uint8',\n",
    "    'ece_flag_cnt': 'uint8',\n",
    "    'down_up_ratio': 'uint16',\n",
    "    'pkt_size_avg': 'float32',\n",
    "    'fwd_seg_size_avg': 'float32',\n",
    "    'bwd_seg_size_avg': 'float32',\n",
    "    'fwd_byts_b_avg': 'uint8',\n",
    "    'fwd_pkts_b_avg': 'uint8',\n",
    "    'fwd_blk_rate_avg': 'uint8',\n",
    "    'bwd_byts_b_avg': 'uint8',\n",
    "    'bwd_pkts_b_avg': 'uint8',\n",
    "    'bwd_blk_rate_avg': 'uint8',\n",
    "    'subflow_fwd_pkts': 'uint32',\n",
    "    'subflow_fwd_byts': 'uint32',\n",
    "    'subflow_bwd_pkts': 'uint32',\n",
    "    'subflow_bwd_byts': 'uint32',\n",
    "    'init_fwd_win_byts': 'int32',\n",
    "    'init_bwd_win_byts': 'int32',\n",
    "    'fwd_act_data_pkts': 'uint32',\n",
    "    'fwd_seg_size_min': 'uint8',\n",
    "    'active_mean': 'float32',\n",
    "    'active_std': 'float32',\n",
    "    'active_max': 'uint32',\n",
    "    'active_min': 'uint32',\n",
    "    'idle_mean': 'float32',\n",
    "    'idle_std': 'float32',\n",
    "    'idle_max': 'uint64',\n",
    "    'idle_min': 'uint64',\n",
    "    'label': 'category'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot safely convert passed user dtype of float32 for object dtyped data in column 17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array from dtype('O') to dtype('float32') according to the rule 'safe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-80eb2d87d528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/spark/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/spark/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/spark/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/spark/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot safely convert passed user dtype of float32 for object dtyped data in column 17"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(tmp_file_path, dtype=types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error indicates that column 17 (Flow Byts/s) cannot be parsed. Another visual examination of the file reveals the existence of the string `Infinity` in multiple rows of this column.\n",
    "The `read_csv()` method of pandas is not able to correctly parse this value as it only recognizes the strings `inf/-inf` as a valid representation of infinity.\n",
    "\n",
    "To fix this problem all occurrences of `Infinity` are replaced by the string `inf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/spark/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(tmp_file_path)\n",
    "\n",
    "df_infinity_fixed = df.replace('Infinity', 'inf')\n",
    "\n",
    "tmp_file_path_inf = os.path.join(tmp_path, 'Thursday-01-03-2018_TrafficForML_CICFlowMeter_infinity_fixed.csv')\n",
    "\n",
    "df_infinity_fixed.to_csv(tmp_file_path_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fixing the infinity values the file can successfully be loaded with the given datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(tmp_file_path_inf, dtype=types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 331100 entries, 0 to 331099\n",
      "Data columns (total 82 columns):\n",
      "Unnamed: 0           331100 non-null int64\n",
      "Unnamed: 0.1         331100 non-null int64\n",
      "dst_port             331100 non-null uint32\n",
      "protocol             331100 non-null uint8\n",
      "timestamp            331100 non-null object\n",
      "flow_duration        331100 non-null int64\n",
      "tot_fwd_pkts         331100 non-null uint32\n",
      "tot_bwd_pkts         331100 non-null uint32\n",
      "totlen_fwd_pkts      331100 non-null uint32\n",
      "totlen_bwd_pkts      331100 non-null uint32\n",
      "fwd_pkt_len_max      331100 non-null uint16\n",
      "fwd_pkt_len_min      331100 non-null uint16\n",
      "fwd_pkt_len_mean     331100 non-null float32\n",
      "fwd_pkt_len_std      331100 non-null float32\n",
      "bwd_pkt_len_max      331100 non-null uint16\n",
      "bwd_pkt_len_min      331100 non-null uint16\n",
      "bwd_pkt_len_mean     331100 non-null float32\n",
      "bwd_pkt_len_std      331100 non-null float32\n",
      "flow_byts_s          329266 non-null float32\n",
      "flow_pkts_s          331100 non-null float64\n",
      "flow_iat_mean        331100 non-null float32\n",
      "flow_iat_std         331100 non-null float32\n",
      "flow_iat_max         331100 non-null int64\n",
      "flow_iat_min         331100 non-null int64\n",
      "fwd_iat_tot          331100 non-null int64\n",
      "fwd_iat_mean         331100 non-null float32\n",
      "fwd_iat_std          331100 non-null float32\n",
      "fwd_iat_max          331100 non-null int64\n",
      "fwd_iat_min          331100 non-null int64\n",
      "bwd_iat_tot          331100 non-null uint32\n",
      "bwd_iat_mean         331100 non-null float32\n",
      "bwd_iat_std          331100 non-null float32\n",
      "bwd_iat_max          331100 non-null uint32\n",
      "bwd_iat_min          331100 non-null uint32\n",
      "fwd_psh_flags        331100 non-null uint8\n",
      "bwd_psh_flags        331100 non-null uint8\n",
      "fwd_urg_flags        331100 non-null uint8\n",
      "bwd_urg_flags        331100 non-null uint8\n",
      "fwd_header_len       331100 non-null uint32\n",
      "bwd_header_len       331100 non-null uint32\n",
      "fwd_pkts_s           331100 non-null float64\n",
      "bwd_pkts_s           331100 non-null float32\n",
      "pkt_len_min          331100 non-null uint16\n",
      "pkt_len_max          331100 non-null uint16\n",
      "pkt_len_mean         331100 non-null float32\n",
      "pkt_len_std          331100 non-null float32\n",
      "pkt_len_var          331100 non-null float32\n",
      "fin_flag_cnt         331100 non-null uint8\n",
      "syn_flag_cnt         331100 non-null uint8\n",
      "rst_flag_cnt         331100 non-null uint8\n",
      "psh_flag_cnt         331100 non-null uint8\n",
      "ack_flag_cnt         331100 non-null uint8\n",
      "urg_flag_cnt         331100 non-null uint8\n",
      "cwe_flag_count       331100 non-null uint8\n",
      "ece_flag_cnt         331100 non-null uint8\n",
      "down_up_ratio        331100 non-null uint16\n",
      "pkt_size_avg         331100 non-null float32\n",
      "fwd_seg_size_avg     331100 non-null float32\n",
      "bwd_seg_size_avg     331100 non-null float32\n",
      "fwd_byts_b_avg       331100 non-null uint8\n",
      "fwd_pkts_b_avg       331100 non-null uint8\n",
      "fwd_blk_rate_avg     331100 non-null uint8\n",
      "bwd_byts_b_avg       331100 non-null uint8\n",
      "bwd_pkts_b_avg       331100 non-null uint8\n",
      "bwd_blk_rate_avg     331100 non-null uint8\n",
      "subflow_fwd_pkts     331100 non-null uint32\n",
      "subflow_fwd_byts     331100 non-null uint32\n",
      "subflow_bwd_pkts     331100 non-null uint32\n",
      "subflow_bwd_byts     331100 non-null uint32\n",
      "init_fwd_win_byts    331100 non-null int32\n",
      "init_bwd_win_byts    331100 non-null int32\n",
      "fwd_act_data_pkts    331100 non-null uint32\n",
      "fwd_seg_size_min     331100 non-null uint8\n",
      "active_mean          331100 non-null float32\n",
      "active_std           331100 non-null float32\n",
      "active_max           331100 non-null uint32\n",
      "active_min           331100 non-null uint32\n",
      "idle_mean            331100 non-null float32\n",
      "idle_std             331100 non-null float32\n",
      "idle_max             331100 non-null uint64\n",
      "idle_min             331100 non-null uint64\n",
      "label                331100 non-null category\n",
      "dtypes: category(1), float32(22), float64(2), int32(2), int64(8), object(1), uint16(7), uint32(17), uint64(2), uint8(20)\n",
      "memory usage: 95.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinity values of flow_byts_s: 1085\n",
      "Null values of flow_byts_s: 1834\n"
     ]
    }
   ],
   "source": [
    "print(f\"Infinity values of flow_byts_s: {df[df['flow_byts_s'] == np.inf]['dst_port'].count()}\")\n",
    "print(f\"Null values of flow_byts_s: {df[df['flow_byts_s'].isnull()]['dst_port'].count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cleanup Script\n",
    "\n",
    "In summary the following clean-up steps must be applied to all files of the dataset:\n",
    "1. Removal of duplicate headers contained as rows of the dataset.\n",
    "2. Substitution of occurrences of `Infinity` with `inf`\n",
    "3. Renaming the column names to remove whitespaces and non-word characters\n",
    "\n",
    "The following script processes all files of the dataset and stores the output files using a name describing the attack types of the flows contained in the files rather than the date of the flows.\n",
    "\n",
    "Remark: The file `Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv` contains four columns (`Flow ID`, `Src IP`, `Dst IP`, `Src Port`) not present in any of the other files. As those columns are not required they are dropped upon loading the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "csv_files = {\n",
    " 'Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv': 'infiltration_28-02-2018.csv',\n",
    " 'Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv': 'infiltration_01-03-2018.csv',\n",
    " 'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv': 'bot_02-03-2018.csv',\n",
    " 'Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv': 'bruteforce-web-xss_sql-injection_22-02-2018.csv',\n",
    " 'Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv': 'dos-goldeneye-slowloris_15-02-2018.csv',\n",
    " 'Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv': 'ddos-loic-http-loic-udp_20-02-2018.csv',\n",
    " 'Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv': 'ddos-loic-udp_hoic_21-02-2018.csv',\n",
    " 'Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv': 'bruteforce-ftp-ssh_14-02-2018.csv',\n",
    " 'Friday-16-02-2018_TrafficForML_CICFlowMeter.csv': 'dos-slowhttp-hulk_16-02-2018.csv',\n",
    " 'Friday-23-02-2018_TrafficForML_CICFlowMeter.csv': 'bruteforce-web-xss_sql-injection_23-02-2018.csv'\n",
    "}\n",
    "\n",
    "column_name_regex = re.compile(r\"\\W\", re.IGNORECASE)\n",
    "processed_dir = 'processed'\n",
    "processed_path = os.path.join(dataset_base_path, processed_dir)\n",
    "\n",
    "def remove_headers(f):    \n",
    "    return f[~f['Dst Port'].str.contains('Dst Port', na=False)]\n",
    "\n",
    "def replace_infinity(f):\n",
    "    return f.replace('Infinity', 'inf', inplace=True)\n",
    "\n",
    "def remove_non_word_chars_from_column_names(f):\n",
    "    return [column_name_regex.sub('_', c.lower()) for c in df.columns]\n",
    "    \n",
    "if not os.path.exists(processed_path):\n",
    "    os.mkdir(processed_path)    \n",
    "    \n",
    "for f, out in csv_files.items():\n",
    "    file_path = os.path.join(dataset_base_path, f)\n",
    "    output_path = os.path.join(dataset_base_path, processed_dir, out)\n",
    "    \n",
    "    df = pd.read_csv(file_path, dtype=str).drop(columns=['Flow ID', 'Src IP', 'Dst IP', 'Src Port'], errors='ignore')\n",
    "    df = remove_headers(df)\n",
    "    replace_infinity(df)\n",
    "    df.columns = remove_non_word_chars_from_column_names(df)\n",
    "    df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
